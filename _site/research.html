<!-- Lastly modified by Hanlin CAI in 2023/04/26 -->
<!-- It is not recommended to modify this code, unless you are a Pro-->

<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->

<head>
<!-- It is not recommended to modify this code, unless you are a Pro-->
<!-- Lastly modified by Hanlin CAI in 2023/04/26 -->

<meta charset="utf-8">
<title>Research Projects &#8211; Rohan Tan Bhowmik</title>



<meta property="og:locale" content="en_US">
<meta property="og:title" content="Research Projects &#8211; Rohan Tan Bhowmik">
<meta property="og:description" content="A multi-modal wildfire prediction and early-warning system based on a novel machine learning frameworkWildfires are i...">
<meta property="og:url" content="http://localhost:4000/research">
<meta property="og:site_name" content="Rohan Tan Bhowmik">

<!-- Webmaster Tools verfication -->
<meta name="google-site-verification" content="pXyzRgze0rJI04BJLOfwhWVkqnMlE-wTU5OzlMif-C8">



<link rel="canonical" href="http://localhost:4000/research">



<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">


<!-- Google Webfonts -->
<link href='https://fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700|PT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous" />

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if (lt IE 9) & (!IEMobile)]>
<link rel="stylesheet" href="/assets/css/ie.css">
<![endif]-->

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.8.3/modernizr.min.js" integrity="sha512-3n19xznO0ubPpSwYCRRBgHh63DrV+bdZfHK52b1esvId4GsfwStQNPJFjeQos2h3JwCmZl0/LgLxSKMAI55hgw==" crossorigin="anonymous"></script>

<!-- 16x16 -->
<link rel="shortcut icon" href="http://localhost:4000/images/fav.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://localhost:4000/images/fav.jpg">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://localhost:4000/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://localhost:4000/images/fav.jpg">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://localhost:4000/images/fav.jpg">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://localhost:4000/images/fav.jpg">

<script src="https://cdn.counter.dev/script.js" data-id="4c8f7caa-2b55-46cd-a995-2c4633303773" data-utcoffset="8"></script>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-T5N5JY1E21"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-T5N5JY1E21');
</script>

</head>


<body class="page" itemscope itemtype="http://schema.org/WebPage">

<!-- [if lt IE 6]><div class="chrome-frame alert alert-info"><strong>Your browser is really old!</strong> <a href="http://browsehappy.com/">Why not upgrade to a different browser</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better enjoy this site?</div><![endif] -->

<!-- It is not recommended to modify this code, unless you are a Pro-->
<!-- Lastly modified by Hanlin CAI in 2023/01/15 -->

<div class="navigation-wrapper">
	<div class="site-name">
		<a href="http://localhost:4000">Rohan Tan Bhowmik</a>
	</div><!-- /.site-name -->
  
	<div class="top-navigation">
		<nav role="navigation" itemscope itemtype="http://schema.org/SiteNavigationElement">
		    <ul>
		        
            <li><a href="http://localhost:4000/" >About Me</a></li>
		        
            <li><a href="http://localhost:4000/publications/" >Publications</a></li>
		        
            <li><a href="http://localhost:4000/research/" >Research</a></li>
		        
            <li><a href="http://localhost:4000/awards/" >Awards</a></li>
		        
		    </ul>
		</nav>
	</div><!-- /.top-navigation -->
</div><!-- /.navigation-wrapper -->

<!-- Lastly modified by Hanlin CAI in 2023/05/01 -->



<div id="main" role="main"  itemprop="mainContentOfPage">
  <div class="article-author-top">
    <img src="http://localhost:4000/images/fav.jpg" class="bio-photo" alt="Rohan Tan Bhowmik bio photo" width="100" height="100"></a>

<!-- <h4>Rohan Tan Bhowmik</h4> -->

<p></p>

<p style="text-indent:0;margin-top:1.5em;"><a href="mailto:rohan.t.bhowmik@gmail.com" target="_blank"><i class="icon-mail"></i> Email</a></p>

<p style="text-indent:0;"><a href="http://rohan-tan-bhowmik.github.io/file/resume.pdf"><img src="https://caihanlin.com/images/logo/icons8-cv-100.png" width="16.5" height="16.5"></i> My CV</a></p>







<p style="text-indent:0;"><a href="https://linkedin.com/in/rohan-tan-bhowmik-045911126"><i class="icon-linkedin"></i> LinkedIn</a></p>



<p style="text-indent:0;"><a href="https://github.com/rohan-tan-bhowmik"><i class="icon-github"></i> Github</a></p>





<p style="text-indent:0;"><a href="https://scholar.google.com/citations?user=srDA_EYAAAAJ"><i class="ai ai-google-scholar-square"></i> Google Scholar</a></p>

<p style="text-indent:0;"><a href="https://www.researchgate.net/profile/Rohan-Bhowmik"><img src="https://caihanlin.com/images/logo/icons8-rg.png" width="14" height="14"></i> ResearchGate</a></p>






<!-- Lastly modified by Hanlin CAI in 2023/10/15 -->
  </div>
  <article itemscope itemtype="http://schema.org/CreativeWork">
  
    <div class="article-wrap" itemprop="text">
      <h2>A multi-modal wildfire prediction and early-warning system based on a novel machine learning framework</h2>

<p><img src="/images/research-jenvman.jpg" />
<br />
Wildfires are increasingly impacting the environment and human health. Among the top 20 California wildfires, those in 2020–2021 burned more acres than the last century combined. Lack of an adequate early warning system impacts the health and safety of vulnerable populations disproportionately and widens the inequality gap. In this project, a multi-modal wildfire prediction and early warning system has been developed based on a novel spatio-temporal machine learning architecture. A comprehensive wildfire database with over 37 million data points was created, including the historical wildfires, environmental and meteorological sensor data from the Environmental Protection Agency, and geological data. The data was augmented into 2.53 km × 2.53 km square grids to overcome the sensor network coverage limitations. Leading and trailing indicators for the wildfires are proposed, classified, and tested. The leading indicators are correlated to the risks of wildfire conception, whereas the trailing indicators are correlated to the byproducts of the wildfires. Additionally, geological data was incorporated to provide additional information for better assessment on wildfire risks and propagation. Next, a novel U-Convolutional Long Short-Term Memory (ULSTM) neural network was developed to extract key spatial and temporal features of the dataset, specifically to address the spatial nature of the location of the wildfire and time-progression temporal nature of the wildfire evolution. Through iterative improvements and optimization, the final ULSTM network architecture, trained with data from 2012 to 2017, achieved &gt;97% accuracy for predicting wildfires in 2018, as compared to ∼76% using traditional Convolutional Neural Network (CNN) techniques. The final model was applied to conduct a retrospective study for the 2018–2022 wildfire seasons, and successfully predicted 85.7% of wildfires &gt;300 K acres in size. This technique could enable fire departments to anticipate and prevent wildfires before they strike and provide early warnings for at-risk individuals for better preparation, thereby saving lives, protecting the environment, and avoiding economic damages.</p>

<p>Links: <a href="https://doi.org/10.1016/j.jenvman.2023.117908">Paper</a> and <a href="https://www.youtube.com/watch?v=BrrxihmmZis">Presentation</a></p>

<hr />

<h2>Automating the Standardized Cosmesis and Health Nasal Outcomes Survey Classification with Convolutional Neural Networks</h2>

<p><img src="/images/research-fpsam.png" height="650" />
<br />
Currently, the aesthetic appearance and structure of the nose in a rhinoplasty patient is evaluated by a surgeon, without automation. This paper compares the assessment of convolutional neural networks (CNNs) (machine learning) and a rhinoplasty surgeon’s impression of the nose before rhinoplasty. Preoperative nasal images were scored using a modified standardized cosmesis and health nasal outcomes survey (SCHNOS) questionnaire. Artificial intelligence (AI) models based on CNNs were developed and trained to classify patient nasal aesthetics into one of five categories, representing even intervals on the SCHNOS scoring scale. The models’ performances were benchmarked against expert surgeon evaluation. Two hundred thirty-five preoperative patient images were included in the study. The best-performing AI model achieved 61% accuracy and 0.449 average Matthews Correlation Coefficient on new patients. This pilot study suggests a proof-of-concept for AI to allow an automated patient assessment tool trained on preoperative patient images with a potential utility for counseling rhinoplasty patients.</p>

<p>Link: <a href="https://www.liebertpub.com/doi/10.1089/fpsam.2022.0306">Paper</a></p>

<hr />

<h2>A Multi-Modal Respiratory Disease Exacerbation Prediction Technique Based on a Spatio-Temporal Machine Learning Architecture</h2>

<p><img src="/images/research-electronics.png" />
<br />
Chronic respiratory diseases, such as the Chronic Obstructive Pulmonary Disease (COPD) and asthma, are a serious health crisis, affecting a large number of people globally and inflicting major costs on the economy. Current methods for assessing the progression of respiratory symptoms are either subjective and inaccurate, or complex and cumbersome, and do not incorporate environmental factors to track individualized risks. Lacking predictive assessments and early intervention, unexpected exacerbations often lead to hospitalizations and high medical costs. This work presents a multi-modal solution for predicting the exacerbation risks of respiratory diseases, such as COPD, based on a novel spatio-temporal machine learning architecture for real-time and accurate respiratory events detection, and tracking of local environmental and meteorological data and trends. The proposed new neural network model blends key attributes of both convolutional and recurrent neural architectures, allowing extraction of the salient spatial and temporal features encoded in respiratory sounds, thereby leading to accurate classification and tracking of symptoms. Combined with the data from environmental and meteorological sensors, and a predictive model based on retrospective medical studies, this solution can assess and provide early warnings of respiratory disease exacerbations, thereby potentially reducing hospitalization rates and medical costs.</p>

<p>Links: <a href="https://doi.org/10.3390/electronics11162562">Paper</a> and <a href="https://www.youtube.com/watch?v=2v78ReRNDVg">Presentation</a></p>

<hr />

<h2>Quantum Optical Convolutional Neural Network: A Novel Image Recognition Framework for Quantum Computing</h2>

<p><img src="/images/research-ieee.png" />
<br />
Large machine learning models based on Convolutional Neural Networks (CNNs) with rapidly increasing numbers of parameters are being deployed in a wide array of computer vision tasks. However, the insatiable demand for computing resources required to train these models is fast outpacing the advancement of classical computing hardware, and new frameworks including Optical Neural Networks (ONNs) and quantum computing are being explored as future alternatives. In this work, we report a novel quantum computing based deep learning model, the Quantum Optical Convolutional Neural Network (QOCNN), to alleviate the computational bottleneck in future computer vision applications. Using the MNIST dataset, we have benchmarked this new architecture against a traditional CNN model based on the seminal LeNet architecture. We have also compared the performance against previously reported ONNs, the GridNet and ComplexNet, and a Quantum Optical Neural Network (QONN) that we built by combining the ComplexNet with quantum-inspired sinusoidal nonlinearities. Our work extends the prior research on QONN by adding quantum convolution and pooling layers. We have evaluated the models using the metrics of accuracies, confusion matrices, Receiver Operating Characteristic curves, and Matthews Correlation Coefficients. The performance of the models were similar, and the metrics indicated that the new QOCNN model is robust. Finally, we estimated the gains in computational efficiencies from executing this novel framework on a quantum computer, concluding that switching to a quantum computing based approach to deep learning may result in comparable accuracies to classical models while simultaneously achieving unprecedented boosts in computational performances and power allocation.</p>

<p>Link: <a href="https://ieeexplore.ieee.org/document/9492087">Paper</a></p>

    </div><!-- /.article-wrap -->
  </article>
</div><!-- /#index -->

<div class="footer-wrap">
  <footer>
    <h6>&copy; 2024 Rohan Tan Bhowmik.
  Published with <a href="https://pages.github.com/" rel="nofollow">GitHub Pages</a>,
  powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a>,
  based on the <a href="https://mademistakes.com/" rel="nofollow">Minimal Mistakes</a> theme.
  Source code for this website can be found <a href="https://github.com/GuangLun2000/GuangLun2000.github.io" rel="nofollow">here</a>.

  <!-- <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=tGZ_4852x6Mm-PPomoo98e4y_CI8D9TmioGTO03Daik"></script> -->
  
</h6>


<!-- Lastly modified by Hanlin CAI in 2023/03/16 -->
  </footer>
</div><!-- /.footer-wrap -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://localhost:4000/assets/js/main.min.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'G-T5N5JY1E21', 'caihanlin.com');
  ga('send', 'pageview');

</script>

<!-- https://analytics.google.com/analytics/ -->
<!-- Lastly modified by Hanlin CAI in 2023/01/15 -->

</body>
</html>